# -*- coding: utf-8 -*-
"""Handwritten_Character_Recognition_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tsNEi88339A2dvBq4zc5KeowXSgJbeRI

# Handwritten Character Recognition model
We will use the EMNIST dataset that includes handwritten letters.
"""

#Importing required modules

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models

"""### Load the EMNIST Dataset (Letters)"""

import tensorflow_datasets as tfds

#Load the 'menist/letters' dataset
(ds_train, ds_test), ds_info = tfds.load(
    'emnist/letters',
    split=['train','test'],
    shuffle_files=True,
    as_supervised=True,
    with_info=True
)

"""### Normalize the Data"""

def normalize_img(image,label):
  image=tf.cast(image,tf.float32)/255.0
  return image,label

#Apply the normalization
ds_train=ds_train.map(normalize_img)
ds_test=ds_test.map(normalize_img)

"""### Prepare the dataset for training"""

batch_size=64

# Shuffle, batch and prefetch for better performance
ds_train=ds_train.shuffle(buffer_size=10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)
ds_test=ds_test.batch(batch_size).prefetch(tf.data.AUTOTUNE)

"""### Build the model"""

model = models.Sequential([
    layers.Input(shape=(28, 28, 1)),                # Input shape for grayscale 28x28 image
    layers.Conv2D(32, (3, 3), activation='relu'),   # Conv layer with 32 filters
    layers.MaxPooling2D((2, 2)),                    # Downsample the image
    layers.Conv2D(64, (3, 3), activation='relu'),   # Another conv layer
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),                               # Flatten to 1D vector
    layers.Dense(128, activation='relu'),           # Dense layer with 128 neurons
    layers.Dense(27, activation='softmax')          # Output layer (26 letters + 1 unknown = 27)
])

"""### Compile the model"""

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

"""### Train the model"""

model.fit(ds_train, epochs=5, validation_data=ds_test)

"""### Evalute the model"""

test_loss, test_acc = model.evaluate(ds_test)
print(f"\nTest Accuracy: {test_acc:.2f}")

"""### Predict a Sample Image"""

for image, label in ds_test.take(1):  # Take one batch
    plt.imshow(image[0].numpy().squeeze(), cmap='gray')  # Show first image
    plt.title("Actual Label: " + str(label[0].numpy()))
    plt.show()

    prediction = model.predict(tf.expand_dims(image[0], 0))  # Predict single image
    predicted_label = np.argmax(prediction)
    print("Predicted Label:", predicted_label)

"""### EMNIST labels start from 1 to 26 (i.e., A=1, B=2, ..., Z=26). So, to get actual letters:"""

print("Predicted Character:", chr(predicted_label + 64))  # A=65 in ASCII